{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import datasets\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, Layer\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining training and testing datasets\n",
    "(x_train, y_train), (x_test,y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 4th dimension as 1 to declare as grayscale image\n",
    "#normalizing the images\n",
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1'),\n",
    "    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_2'),\n",
    "    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_3'),\n",
    "    tf.keras.layers.Flatten(name='flatten'),\n",
    "    #tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determining the weight and bias shape of convolutional layers\n",
    "convW,convB = model.layers[0].get_weights()\n",
    "\n",
    "convW.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.01900043,  0.03672551,  0.0430087 , -0.13929585,\n",
       "           0.02883182,  0.04263088,  0.01293938, -0.03313406,\n",
       "           0.07048923, -0.05301746,  0.10666698, -0.02829881,\n",
       "          -0.07272732, -0.03026661,  0.02928135, -0.14199668,\n",
       "          -0.0850064 , -0.07997881,  0.08467892,  0.06201228,\n",
       "           0.08452182, -0.01717522,  0.1161408 , -0.0833247 ,\n",
       "           0.08158541,  0.10179327,  0.12613453,  0.02084211,\n",
       "          -0.10489421,  0.08390069,  0.01112579,  0.05707273]],\n",
       "\n",
       "        [[ 0.07412748, -0.04612972, -0.11925267, -0.11221708,\n",
       "           0.12124406,  0.05095209, -0.06402098, -0.10834963,\n",
       "           0.05150186,  0.14169027,  0.02309148, -0.02917321,\n",
       "           0.03705564,  0.07582906,  0.08366331, -0.02029391,\n",
       "           0.03072931, -0.03979641,  0.14169805, -0.05382916,\n",
       "           0.01708972, -0.04153989,  0.06078301, -0.1278096 ,\n",
       "          -0.05652642,  0.00462346, -0.04426724, -0.11840563,\n",
       "           0.05927421, -0.02479486, -0.12925896,  0.02869645]],\n",
       "\n",
       "        [[-0.02697328,  0.02520314, -0.02680414,  0.08968011,\n",
       "           0.04041405, -0.05491308,  0.12008129,  0.12014921,\n",
       "          -0.12010287, -0.13518207,  0.13880713,  0.00544369,\n",
       "           0.03327116,  0.05575691, -0.0594795 , -0.11766455,\n",
       "          -0.0373873 , -0.05555095,  0.09779344, -0.05853184,\n",
       "          -0.12567379, -0.12764251,  0.0851447 , -0.04456084,\n",
       "          -0.11012574, -0.08321802, -0.10512535, -0.1196885 ,\n",
       "          -0.11721093, -0.11086553,  0.04752889,  0.13271524]]],\n",
       "\n",
       "\n",
       "       [[[ 0.07878953,  0.02425951,  0.05298313,  0.08727421,\n",
       "           0.082203  , -0.0079031 , -0.02635497,  0.13407882,\n",
       "           0.12607192,  0.12540902, -0.07280123, -0.04504766,\n",
       "           0.10045008, -0.08003516,  0.08408274,  0.07339382,\n",
       "          -0.06417734,  0.0305984 , -0.03892852,  0.05548544,\n",
       "          -0.11898239, -0.02849255, -0.13938443, -0.02870888,\n",
       "           0.0128144 ,  0.13128056,  0.0648212 ,  0.0776908 ,\n",
       "           0.02209231,  0.06406236, -0.0287184 ,  0.05799893]],\n",
       "\n",
       "        [[ 0.01045211,  0.1306581 , -0.07310788,  0.1407998 ,\n",
       "          -0.03427203,  0.0598748 ,  0.13804744,  0.09458357,\n",
       "           0.06328003,  0.0547778 ,  0.04495461, -0.02944668,\n",
       "           0.04044323,  0.06523584,  0.02929313, -0.01736848,\n",
       "          -0.12545471, -0.06693319, -0.13805303,  0.00080299,\n",
       "           0.05302434,  0.07254785,  0.09933729,  0.13592757,\n",
       "          -0.13114578, -0.02327505,  0.02496281, -0.04185253,\n",
       "          -0.05588806,  0.04320243, -0.13650665,  0.06020358]],\n",
       "\n",
       "        [[ 0.07504995, -0.08625945, -0.09185947, -0.00221796,\n",
       "          -0.0372531 ,  0.04693215,  0.05873649,  0.07560459,\n",
       "          -0.04945976,  0.01627368,  0.07105471,  0.12804948,\n",
       "          -0.12937059, -0.13053153,  0.05558714,  0.03102277,\n",
       "          -0.04770826, -0.06507955, -0.12817264,  0.03435235,\n",
       "           0.0533437 ,  0.10517624,  0.01012106, -0.08514845,\n",
       "          -0.11574076, -0.08159259, -0.02085078, -0.0337319 ,\n",
       "          -0.01591021, -0.06618001, -0.05930132,  0.09450391]]],\n",
       "\n",
       "\n",
       "       [[[ 0.02333398, -0.1371053 ,  0.08992819, -0.06225277,\n",
       "           0.08948454, -0.00821429,  0.07150321,  0.05716135,\n",
       "          -0.08966049,  0.01774883,  0.13579468, -0.04771952,\n",
       "          -0.13099197,  0.11445974, -0.03975108,  0.12255298,\n",
       "           0.06921798,  0.05512014, -0.07181534,  0.03374465,\n",
       "          -0.00304146, -0.09052323, -0.00400335, -0.09160525,\n",
       "          -0.05728984,  0.09414856,  0.04172386, -0.0494435 ,\n",
       "          -0.05909058, -0.02730096,  0.02486677, -0.02919544]],\n",
       "\n",
       "        [[ 0.05772567,  0.04272957,  0.07533684, -0.06669764,\n",
       "          -0.04973893, -0.10889159, -0.05252538,  0.03019969,\n",
       "          -0.08561485,  0.02645873, -0.04834639,  0.03859125,\n",
       "          -0.13753608,  0.0846048 ,  0.07880196,  0.11662604,\n",
       "           0.0778704 , -0.08420208,  0.06342979,  0.01543054,\n",
       "          -0.10814705,  0.06127903,  0.1142828 , -0.10657413,\n",
       "          -0.11606059,  0.00942828, -0.03772569,  0.12057357,\n",
       "          -0.04514208, -0.01451941, -0.12543742,  0.01760535]],\n",
       "\n",
       "        [[-0.12200948,  0.00611013,  0.05284992,  0.04393364,\n",
       "           0.0797141 , -0.03915794,  0.0099256 ,  0.09823026,\n",
       "          -0.05850223, -0.10061569, -0.07682667, -0.12564902,\n",
       "          -0.0253049 , -0.02180704,  0.10840063,  0.05902952,\n",
       "          -0.01943066, -0.12959415, -0.03649538, -0.00649413,\n",
       "           0.04631332, -0.11055478, -0.02599695,  0.06297946,\n",
       "           0.00513458, -0.11004816, -0.07192165,  0.1131907 ,\n",
       "          -0.0866904 , -0.08117875,  0.10415776,  0.09229949]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting initial filter matrices\n",
    "\n",
    "filter_matrices = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, Conv2D):\n",
    "        weights, biases = layer.get_weights()\n",
    "        filter_matrices.append(weights)\n",
    "        \n",
    "filter_matrices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 13s 7ms/step - loss: 10.2937 - accuracy: 0.0955 - val_loss: 9.9819 - val_accuracy: 0.0980\n"
     ]
    }
   ],
   "source": [
    "# Train the model and display the activations after each epoch\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 9.9819 - accuracy: 0.0980 - 1s/epoch - 3ms/step\n",
      "Test accuracy: 0.09799999743700027\n",
      "Time elapsed:  13.121060132980347\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Time elapsed: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Matrix Extraction and Filter Activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_matrices = []\n",
    "filter_activations = [] \n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, Conv2D):\n",
    "        weights, biases = layer.get_weights()\n",
    "        filter_matrices.append(weights)\n",
    "        \n",
    "        activation_func = K.function([model.input], [layer.output])\n",
    "        activations = np.mean(activation_func([x_train]), axis=(0, 1, 2))\n",
    "        filter_activations.append(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-5.86104728e-02, -1.10076042e-02, -1.27518103e-02,\n",
       "           -1.81280479e-01, -4.90751192e-02, -7.04282802e-03,\n",
       "           -3.01601347e-02, -9.97914672e-02, -5.92099363e-03,\n",
       "           -1.18865274e-01,  2.49268301e-02, -4.79805656e-02,\n",
       "           -1.04117543e-01, -7.06270114e-02, -2.81581152e-02,\n",
       "           -1.96675867e-01, -1.09621972e-01, -1.01126775e-01,\n",
       "           -1.34170363e-02,  1.57254543e-02,  2.89389417e-02,\n",
       "           -4.50095050e-02,  3.28611508e-02, -1.12521715e-01,\n",
       "            3.67065221e-02,  4.34907386e-03,  5.07714115e-02,\n",
       "           -1.96193904e-02, -1.19913779e-01,  3.01126707e-02,\n",
       "           -6.38457900e-03, -2.14626566e-02]],\n",
       " \n",
       "         [[ 3.39477360e-02, -8.87670740e-02, -1.53255105e-01,\n",
       "           -1.59266099e-01,  4.49395776e-02, -1.28322106e-03,\n",
       "           -1.23752557e-01, -1.81632310e-01, -2.17473432e-02,\n",
       "            4.43320945e-02, -5.91279194e-02, -6.34492040e-02,\n",
       "            2.69537471e-04,  2.36512963e-02,  2.69017126e-02,\n",
       "           -5.65886311e-02,  9.23060533e-03, -5.32254912e-02,\n",
       "            4.37630303e-02, -8.31009448e-02, -2.72845980e-02,\n",
       "           -7.54226744e-02, -2.49306578e-02, -1.49941698e-01,\n",
       "           -9.11352485e-02, -8.61214548e-02, -1.03776298e-01,\n",
       "           -1.47868067e-01,  2.82130335e-02, -6.69491962e-02,\n",
       "           -1.51962534e-01, -5.69426231e-02]],\n",
       " \n",
       "         [[-6.38271719e-02, -1.31391117e-03, -4.79329638e-02,\n",
       "            2.21654717e-02, -1.84401814e-02, -8.36440250e-02,\n",
       "            2.74581350e-02,  3.36909816e-02, -1.63505033e-01,\n",
       "           -1.80205926e-01,  4.00150791e-02, -4.86612841e-02,\n",
       "            8.73793557e-04,  9.23447963e-03, -1.13468334e-01,\n",
       "           -1.61770999e-01, -6.00281693e-02, -7.12534040e-02,\n",
       "           -1.99193630e-04, -7.81148225e-02, -1.50043562e-01,\n",
       "           -1.65755793e-01,  2.84167472e-03, -6.56823739e-02,\n",
       "           -1.33170173e-01, -1.33814648e-01, -1.33912608e-01,\n",
       "           -1.54868767e-01, -1.32954895e-01, -1.35398567e-01,\n",
       "           -8.04290269e-03,  3.71331088e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.73442082e-02, -2.59489100e-02, -8.56646243e-03,\n",
       "            1.43412156e-02,  4.77414625e-03, -3.99722978e-02,\n",
       "           -7.71613941e-02,  4.73729186e-02,  4.88507263e-02,\n",
       "            3.22296098e-02, -1.35017201e-01, -6.21719696e-02,\n",
       "            4.15213555e-02, -1.27933264e-01,  2.60235108e-02,\n",
       "           -1.65618137e-02, -9.92633998e-02, -2.65051913e-03,\n",
       "           -1.22636907e-01,  1.07955597e-02, -1.48153350e-01,\n",
       "           -6.87381253e-02, -1.92794651e-01, -7.91878402e-02,\n",
       "           -2.65290216e-02,  3.39674577e-02, -8.78260750e-03,\n",
       "            2.95703951e-02,  6.64080447e-03,  1.29273590e-02,\n",
       "           -4.30227146e-02, -1.65157411e-02]],\n",
       " \n",
       "         [[-3.95970382e-02,  5.24921939e-02, -1.19583547e-01,\n",
       "            6.63161203e-02, -9.10638869e-02,  6.30600983e-03,\n",
       "            5.54853231e-02,  7.41949631e-03, -1.81569427e-03,\n",
       "           -3.06517556e-02, -2.19548158e-02, -6.27178699e-02,\n",
       "           -7.86459073e-03,  1.14771780e-02, -3.08722313e-02,\n",
       "           -1.01887897e-01, -1.52307674e-01, -9.04151201e-02,\n",
       "           -2.09389433e-01, -2.88873147e-02,  2.36016642e-02,\n",
       "            2.97221076e-03,  2.67415307e-02,  4.67667542e-02,\n",
       "           -1.56162649e-01, -1.09971531e-01, -2.54546478e-02,\n",
       "           -9.17834118e-02, -6.86150715e-02,  6.40603062e-03,\n",
       "           -1.57213688e-01, -2.47886200e-02]],\n",
       " \n",
       "         [[ 2.91999560e-02, -1.18628792e-01, -1.29706278e-01,\n",
       "           -7.15783983e-02, -8.21436048e-02, -1.19371910e-03,\n",
       "           -3.22353579e-02, -1.23441899e-02, -8.14958885e-02,\n",
       "           -1.99160893e-02, -1.86028872e-02,  5.29360548e-02,\n",
       "           -1.55366138e-01, -1.66539758e-01, -1.06773591e-02,\n",
       "           -4.97733243e-02, -7.21738413e-02, -6.50795549e-02,\n",
       "           -2.05546886e-01,  1.02539789e-02,  1.26023134e-02,\n",
       "            3.26977000e-02, -5.53501807e-02, -1.20628364e-01,\n",
       "           -1.34830460e-01, -1.14028037e-01, -4.33988646e-02,\n",
       "           -9.90712717e-02, -2.09218115e-02, -8.67457613e-02,\n",
       "           -9.87697914e-02, -1.13620306e-03]]],\n",
       " \n",
       " \n",
       "        [[[-2.67671924e-02, -1.62538275e-01,  2.11682897e-02,\n",
       "           -1.15286268e-01,  1.43396463e-02, -3.18992101e-02,\n",
       "            1.83548257e-02, -2.92479135e-02, -1.45374686e-01,\n",
       "           -5.01216538e-02,  5.17163947e-02, -6.62106127e-02,\n",
       "           -1.58116877e-01,  3.19035910e-02, -9.64899883e-02,\n",
       "            2.85556596e-02,  1.28591824e-02,  2.09745225e-02,\n",
       "           -1.07611686e-01, -8.04826710e-03, -2.35333648e-02,\n",
       "           -1.18229091e-01, -5.73797971e-02, -1.15875721e-01,\n",
       "           -8.50582644e-02, -3.32598411e-03, -2.79485937e-02,\n",
       "           -1.16237439e-01, -6.88226670e-02, -6.82241097e-02,\n",
       "            3.79552343e-03, -9.80688632e-02]],\n",
       " \n",
       "         [[ 9.52917896e-03, -2.66051963e-02,  6.68269442e-03,\n",
       "           -1.11097738e-01, -9.81869623e-02, -1.27267614e-01,\n",
       "           -1.04153752e-01, -5.62962331e-02, -1.18395619e-01,\n",
       "           -2.81976461e-02, -1.12437420e-01,  2.02942248e-02,\n",
       "           -1.59348607e-01,  4.79749823e-03,  1.07637467e-02,\n",
       "            2.24722829e-02,  2.21014582e-02, -1.09519027e-01,\n",
       "            3.30459364e-02, -1.57246161e-02, -1.32357180e-01,\n",
       "            1.89036727e-02,  4.44182381e-02, -1.52712002e-01,\n",
       "           -1.35460988e-01, -7.77530149e-02, -8.52352306e-02,\n",
       "            2.89132688e-02, -4.81151082e-02, -4.58073616e-02,\n",
       "           -1.61881313e-01, -6.67863116e-02]],\n",
       " \n",
       "         [[-1.51589409e-01, -3.45175005e-02, -1.26649179e-02,\n",
       "           -2.14446965e-03,  2.60518286e-02, -6.12760074e-02,\n",
       "           -4.57850918e-02,  1.05007077e-02, -8.38339627e-02,\n",
       "           -1.32577971e-01, -1.26860932e-01, -1.48525968e-01,\n",
       "           -5.15308268e-02, -8.09482485e-02,  3.55601534e-02,\n",
       "           -3.48327495e-02, -6.22224845e-02, -1.46902919e-01,\n",
       "           -9.30542052e-02, -3.30893211e-02,  4.41811886e-03,\n",
       "           -1.46103501e-01, -8.48557204e-02,  8.67166650e-03,\n",
       "           -1.12412600e-02, -1.56360090e-01, -1.00663736e-01,\n",
       "            1.95682552e-02, -8.66903961e-02, -1.03119813e-01,\n",
       "            2.09739432e-02, -3.27535113e-03]]]], dtype=float32)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31],\n",
       "        [ 0, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 30, 31]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Rank Filters based on their mean of activation values in the feature map\n",
    "\n",
    "filter_ranks = np.argsort(filter_activations)\n",
    "filter_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: remove Filters\n",
    "num_filters_to_keep = 32  # Number of filters to keep\n",
    "        \n",
    "if isinstance(model.layers[0], tf.keras.layers.Conv2D):\n",
    "    weights, biases = model.layers[0].get_weights()\n",
    "    keep_weights = weights[:, :, :, filter_ranks[-num_filters_to_keep:]]\n",
    "    keep_weights = keep_weights[:,:,:,0,0,:]\n",
    "    keep_biases = biases[filter_ranks[-num_filters_to_keep:]]\n",
    "    keep_biases=keep_biases[0,0,:]\n",
    "    model.layers[0].set_weights([keep_weights, keep_biases])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 9.9819 - accuracy: 0.0980 - 964ms/epoch - 3ms/step\n",
      "Test accuracy: 0.09799999743700027\n",
      "Time elapsed:  13.121060132980347\n"
     ]
    }
   ],
   "source": [
    "#evaluate test dataset after filter manipulation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Time elapsed: ', end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
