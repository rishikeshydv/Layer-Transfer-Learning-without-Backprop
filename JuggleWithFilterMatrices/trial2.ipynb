{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we make a CNN model with 3 conv2D layer, 1 flatten and 1 dense layer. We turn of training in the very beginning and train + evaluate on the training and test dataset. After that, we evaluate 10 most irrelevant filters based upon their average sum of their activations on 3 different axes (0,1,2). '0' takes all the datasets, '1' is along the height, and '2' is along the width. After removing the irrelevant filters, we train+evaluate to check the accuracy and time elapsed on training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rrvt3NUnAYTH"
      },
      "outputs": [],
      "source": [
        "#defining imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras import datasets\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D, Layer\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owOXRt4QAYTI",
        "outputId": "9785ce49-747f-4ca2-a461-69ed11c0918e"
      },
      "outputs": [],
      "source": [
        "# get MNIST fashion\n",
        "from keras.datasets import fashion_mnist\n",
        "(fashion_train_img, fashion_train_labels), (fashion_test_img, fashion_test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p9e8oPlUAYTI"
      },
      "outputs": [],
      "source": [
        "#adding 4th dimension as 1 to declare as grayscale image\n",
        "#normalizing the images\n",
        "fashion_train_img = fashion_train_img.reshape((60000, 28, 28, 1))\n",
        "fashion_train_img = fashion_train_img/255.0\n",
        "\n",
        "fashion_test_img = fashion_test_img.reshape((10000, 28, 28, 1))\n",
        "fashion_test_img = fashion_test_img/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTtBH9-JAYTI"
      },
      "source": [
        "Defining our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eBydXIv3AYTJ"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_2'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_3'),\n",
        "    tf.keras.layers.Flatten(name='flatten'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Turning off Backprop for Conv2D layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in model.layers[:3]:\n",
        "    layer.trainable=False\n",
        "    #print (layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ENJReVMLAYTJ"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_jlqhbAYTK",
        "outputId": "84265d3d-f2c0-4532-b4d8-f525a8030fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1/1875 [..............................] - ETA: 5:46 - loss: 2.3008 - accuracy: 0.0938"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-23 11:39:01.390104: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5746 - accuracy: 0.8081 - val_loss: 0.4752 - val_accuracy: 0.8353\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = model.fit(fashion_train_img, fashion_train_labels, epochs=1, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC3DWd-ZAYTK",
        "outputId": "8c76a2e6-a254-4eea-f171-a1995bfd3f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.4752 - accuracy: 0.8353 - 1s/epoch - 4ms/step\n",
            "Test accuracy: 0.8353000283241272\n",
            "Time elapsed:  10.80650806427002\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(fashion_test_img, fashion_test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 1st Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_1'\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:15]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Convert the weights of the pruned filters to zero\n",
        "weights, biases = model.get_layer(layer_name).get_weights()\n",
        "weights[:, :, :, indices_to_prune] = 0\n",
        "model.get_layer(layer_name).set_weights([weights, biases])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 2nd Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_2'\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:15]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Convert the weights of the pruned filters to zero\n",
        "weights, biases = model.get_layer(layer_name).get_weights()\n",
        "weights[:, :, :, indices_to_prune] = 0\n",
        "model.get_layer(layer_name).set_weights([weights, biases])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 3rd Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 6s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_3'\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:15]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Convert the weights of the pruned filters to zero\n",
        "weights, biases = model.get_layer(layer_name).get_weights()\n",
        "weights[:, :, :, indices_to_prune] = 0\n",
        "model.get_layer(layer_name).set_weights([weights, biases])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4835 - accuracy: 0.8357 - val_loss: 0.4794 - val_accuracy: 0.8294\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = model.fit(fashion_train_img, fashion_train_labels, epochs=1, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pruned accuracy: 0.8446666598320007\n",
            "Time elapsed:  9.936978816986084\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the pruned model\n",
        "_, pruned_accuracy = model.evaluate(fashion_train_img, fashion_train_labels, verbose=0)\n",
        "print('Pruned accuracy:', pruned_accuracy)\n",
        "print('Time elapsed: ', end_time - start_time)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
