{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we make a CNN model with 3 conv2D layer, 1 flatten and 1 dense layer. We turn off training in the very beginning and train + evaluate on the training and test dataset. After that, we evaluate 10 most irrelevant filters based upon their average sum of their activations on 3 different axes (0,1,2). '0' takes all the datasets, '1' is along the height, and '2' is along the width. After removing the irrelevant filters, we train+evaluate to check the accuracy and time elapsed on training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rrvt3NUnAYTH"
      },
      "outputs": [],
      "source": [
        "#defining imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras import datasets\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D, Layer\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owOXRt4QAYTI",
        "outputId": "9785ce49-747f-4ca2-a461-69ed11c0918e"
      },
      "outputs": [],
      "source": [
        "# get MNIST fashion\n",
        "from keras.datasets import fashion_mnist\n",
        "(fashion_train_img, fashion_train_labels), (fashion_test_img, fashion_test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p9e8oPlUAYTI"
      },
      "outputs": [],
      "source": [
        "#adding 4th dimension as 1 to declare as grayscale image\n",
        "#normalizing the images\n",
        "fashion_train_img = fashion_train_img.reshape((60000, 28, 28, 1))\n",
        "fashion_train_img = fashion_train_img/255.0\n",
        "\n",
        "fashion_test_img = fashion_test_img.reshape((10000, 28, 28, 1))\n",
        "fashion_test_img = fashion_test_img/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTtBH9-JAYTI"
      },
      "source": [
        "Defining our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eBydXIv3AYTJ"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',input_shape=(28, 28, 1), name='conv2d_2'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_3'),\n",
        "    tf.keras.layers.Flatten(name='flatten'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Turning off Backprop for Conv2D layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ENJReVMLAYTJ"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_jlqhbAYTK",
        "outputId": "84265d3d-f2c0-4532-b4d8-f525a8030fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3999 - accuracy: 0.8577 - val_loss: 0.3240 - val_accuracy: 0.8850\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2596 - accuracy: 0.9057 - val_loss: 0.2628 - val_accuracy: 0.9083\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.2083 - accuracy: 0.9246 - val_loss: 0.2661 - val_accuracy: 0.9053\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1722 - accuracy: 0.9367 - val_loss: 0.2498 - val_accuracy: 0.9123\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1396 - accuracy: 0.9496 - val_loss: 0.2607 - val_accuracy: 0.9141\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = model.fit(fashion_train_img, fashion_train_labels, epochs=5, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC3DWd-ZAYTK",
        "outputId": "8c76a2e6-a254-4eea-f171-a1995bfd3f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 2s - loss: 0.2607 - accuracy: 0.9141 - 2s/epoch - 5ms/step\n",
            "Test accuracy: 0.9140999913215637\n",
            "Time elapsed:  137.08772587776184\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(fashion_test_img, fashion_test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 1st Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_1'\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
        "\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:10]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Delete the irrelevant filters\n",
        "layer = model.get_layer(layer_name)\n",
        "weights, biases = layer.get_weights()\n",
        "pruned_weights = np.delete(weights, indices_to_prune, axis=3)\n",
        "pruned_biases = np.delete(biases, indices_to_prune, axis=0)\n",
        " \n",
        "\n",
        "# Copying the remaining filters to a new layer, but using the old flatten and dense layer\n",
        "\n",
        "new_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(22, (3, 3), activation='relu', input_shape=(28, 28, 1), name='new_conv2d_1'),\n",
        "])\n",
        "\n",
        "    \n",
        "# Copy the weights and biases of the remaining filters\n",
        "new_layer = new_model.get_layer('new_conv2d_1')\n",
        "new_weights = pruned_weights[:, :, :, :22]\n",
        "new_biases = pruned_biases[:22]\n",
        "\n",
        "new_layer.set_weights([new_weights, new_biases])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 2nd Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 1ms/step\n",
            "1875/1875 [==============================] - 5s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of 'conv2d_1' from the original model\n",
        "activation_model_conv1 = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
        "activations_conv1 = activation_model_conv1.predict(fashion_train_img)\n",
        "\n",
        "# Add 'conv2d_2' to the new model\n",
        "new_model.add(tf.keras.layers.Conv2D(22, (3, 3), activation='relu', name='new_conv2d_2'))\n",
        "\n",
        "# Get the activations of 'conv2d_2' using activations from 'conv2d_1'\n",
        "activation_model_conv2 = tf.keras.models.Model(inputs=model.get_layer('conv2d_1').output, outputs=model.get_layer('conv2d_2').output)\n",
        "activations_conv2 = activation_model_conv2.predict(activations_conv1)  # Pass activations from 'conv2d_1' to 'conv2d_2'\n",
        "\n",
        "# Determine the filter indices with the least activations in 'conv2d_2'\n",
        "filter_activations_conv2 = np.sum(activations_conv2, axis=(0, 1, 2))\n",
        "indices_to_prune_conv2 = np.argsort(filter_activations_conv2)[:10]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Delete the irrelevant filters in 'conv2d_2' layer\n",
        "layer_conv2 = model.get_layer('conv2d_2')\n",
        "weights_conv2, biases_conv2 = layer_conv2.get_weights()\n",
        "pruned_weights_conv2 = np.delete(weights_conv2, indices_to_prune_conv2, axis=3)\n",
        "pruned_biases_conv2 = np.delete(biases_conv2, indices_to_prune_conv2, axis=0)\n",
        "\n",
        "# Set the weights and biases of 'new_conv2d_2'\n",
        "new_layer_conv2 = new_model.get_layer('new_conv2d_2')\n",
        "new_weights_conv2 = pruned_weights_conv2[:, :, :22, :22]\n",
        "new_biases_conv2 = pruned_biases_conv2[:22]\n",
        "new_layer_conv2.set_weights([new_weights_conv2, new_biases_conv2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 3rd Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 1ms/step\n",
            "1875/1875 [==============================] - 5s 3ms/step\n",
            "1875/1875 [==============================] - 4s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of 'conv2d_1' from the original model\n",
        "activation_model_conv1 = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
        "activations_conv1 = activation_model_conv1.predict(fashion_train_img)\n",
        "\n",
        "# Add 'conv2d_2' to the new model\n",
        "new_model.add(tf.keras.layers.Conv2D(22, (3, 3), activation='relu', name='new_conv2d_3'))\n",
        "\n",
        "# Get the activations of 'conv2d_2' using activations from 'conv2d_1'\n",
        "activation_model_conv2 = tf.keras.models.Model(inputs=model.get_layer('conv2d_1').output, outputs=model.get_layer('conv2d_2').output)\n",
        "activations_conv2 = activation_model_conv2.predict(activations_conv1)  # Pass activations from 'conv2d_1' to 'conv2d_2'\n",
        "\n",
        "# Get the activations of 'conv2d_3' using activations from 'conv2d_2'\n",
        "activation_model_conv3 = tf.keras.models.Model(inputs=model.get_layer('conv2d_2').output, outputs=model.get_layer('conv2d_3').output)\n",
        "activations_conv3 = activation_model_conv2.predict(activations_conv2)  # Pass activations from 'conv2d_1' to 'conv2d_2'\n",
        "\n",
        "# Determine the filter indices with the least activations in 'conv2d_2'\n",
        "filter_activations_conv3 = np.sum(activations_conv3, axis=(0, 1, 2))\n",
        "indices_to_prune_conv3 = np.argsort(filter_activations_conv3)[:10]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Delete the irrelevant filters in 'conv2d_2' layer\n",
        "layer_conv3 = model.get_layer('conv2d_3')\n",
        "weights_conv3, biases_conv3 = layer_conv3.get_weights()\n",
        "pruned_weights_conv3 = np.delete(weights_conv3, indices_to_prune_conv3, axis=3)\n",
        "pruned_biases_conv3 = np.delete(biases_conv3, indices_to_prune_conv3, axis=0)\n",
        "\n",
        "# Set the weights and biases of 'new_conv2d_2'\n",
        "new_layer_conv3 = new_model.get_layer('new_conv2d_3')\n",
        "new_weights_conv3 = pruned_weights_conv3[:, :, :22, :22]\n",
        "new_biases_conv3 = pruned_biases_conv3[:22]\n",
        "new_layer_conv3.set_weights([new_weights_conv3, new_biases_conv3])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding a Flatten and Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_model.add(model.get_layer('flatten'))\n",
        "new_model.add(tf.keras.layers.Dense(10, activation='softmax', name='new_output'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "new_model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3533 - accuracy: 0.8738 - val_loss: 0.2893 - val_accuracy: 0.8940\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2346 - accuracy: 0.9155 - val_loss: 0.2663 - val_accuracy: 0.9039\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1947 - accuracy: 0.9289 - val_loss: 0.2627 - val_accuracy: 0.9063\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1650 - accuracy: 0.9398 - val_loss: 0.2635 - val_accuracy: 0.9097\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1404 - accuracy: 0.9487 - val_loss: 0.2624 - val_accuracy: 0.9101\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = new_model.fit(fashion_train_img, fashion_train_labels, epochs=5, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pruned accuracy: 0.910099983215332\n",
            "Time elapsed:  98.7699089050293\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the pruned model\n",
        "_, pruned_accuracy = new_model.evaluate(fashion_test_img, fashion_test_labels, verbose=0)\n",
        "print('Pruned accuracy:', pruned_accuracy)\n",
        "print('Time elapsed: ', end_time - start_time)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
