{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we make a CNN model with 3 conv2D layer, 1 flatten and 1 dense layer. We turn of training in the very beginning and train + evaluate on the training and test dataset. After that, we evaluate 10 most irrelevant filters based upon their average sum of their activations on 3 different axes (0,1,2). '0' takes all the datasets, '1' is along the height, and '2' is along the width. After removing the irrelevant filters, we train+evaluate to check the accuracy and time elapsed on training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "rrvt3NUnAYTH"
      },
      "outputs": [],
      "source": [
        "#defining imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras import datasets\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D, Layer\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owOXRt4QAYTI",
        "outputId": "9785ce49-747f-4ca2-a461-69ed11c0918e"
      },
      "outputs": [],
      "source": [
        "# get MNIST fashion\n",
        "from keras.datasets import fashion_mnist\n",
        "(fashion_train_img, fashion_train_labels), (fashion_test_img, fashion_test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "p9e8oPlUAYTI"
      },
      "outputs": [],
      "source": [
        "#adding 4th dimension as 1 to declare as grayscale image\n",
        "#normalizing the images\n",
        "fashion_train_img = fashion_train_img.reshape((60000, 28, 28, 1))\n",
        "fashion_train_img = fashion_train_img/255.0\n",
        "\n",
        "fashion_test_img = fashion_test_img.reshape((10000, 28, 28, 1))\n",
        "fashion_test_img = fashion_test_img/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTtBH9-JAYTI"
      },
      "source": [
        "Defining our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "eBydXIv3AYTJ"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_2'),\n",
        "    tf.keras.layers.Flatten(name='flatten'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Turning off Backprop for Conv2D layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in model.layers[:3]:\n",
        "    layer.trainable=False\n",
        "    #print (layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "ENJReVMLAYTJ"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_jlqhbAYTK",
        "outputId": "84265d3d-f2c0-4532-b4d8-f525a8030fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3953 - accuracy: 0.8595 - val_loss: 0.3276 - val_accuracy: 0.8862\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = model.fit(fashion_train_img, fashion_train_labels, epochs=1, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC3DWd-ZAYTK",
        "outputId": "8c76a2e6-a254-4eea-f171-a1995bfd3f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.3276 - accuracy: 0.8862 - 1s/epoch - 4ms/step\n",
            "Test accuracy: 0.8862000107765198\n",
            "Time elapsed:  18.401186227798462\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(fashion_test_img, fashion_test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 1st Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 2s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_1'\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:10]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Delete the irrelevant filters\n",
        "layer = model.get_layer(layer_name)\n",
        "weights, biases = layer.get_weights()\n",
        "pruned_weights = np.delete(weights, indices_to_prune, axis=3)\n",
        "pruned_biases = np.delete(biases, indices_to_prune, axis=0)\n",
        " \n",
        "\n",
        "# Copying the remaining filters to a new layer, but using the old flatten and dense layer\n",
        "\n",
        "new_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(22, (3, 3), activation='relu', input_shape=(28, 28, 1), name='new_conv2d_1'),\n",
        "])\n",
        "\n",
        "    \n",
        "# Copy the weights and biases of the remaining filters\n",
        "new_layer = new_model.get_layer('new_conv2d_1')\n",
        "new_weights = pruned_weights[:, :, :, :22]\n",
        "new_biases = pruned_biases[:22]\n",
        "\n",
        "new_layer.set_weights([new_weights, new_biases])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Pruning for 2nd Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the activations of the convolutional layer\n",
        "layer_name = 'conv2d_2'\n",
        "\n",
        "new_model.add(Conv2D(22, (3, 3), activation='relu', name='new_conv2d_2'))\n",
        "\n",
        "activation_model = tf.keras.models.Model(inputs=model.layers[0].input, outputs=model.get_layer(layer_name).output)\n",
        "activations = activation_model.predict(fashion_train_img)\n",
        "\n",
        "# Determine the filter indices with the least activations\n",
        "filter_activations = np.sum(activations, axis=(0, 1, 2))\n",
        "indices_to_prune = np.argsort(filter_activations)[:10]  # Prune the 10 filters with the least activations\n",
        "\n",
        "# Delete the irrelevant filters\n",
        "layer = model.get_layer(layer_name)\n",
        "weights, biases = layer.get_weights()\n",
        "pruned_weights = np.delete(weights, indices_to_prune, axis=3)\n",
        "pruned_biases = np.delete(biases, indices_to_prune, axis=0)\n",
        "\n",
        "# Copy the weights and biases of the remaining filters\n",
        "new_layer = new_model.get_layer('new_conv2d_2')\n",
        "new_layer_weights, new_layer_biases = new_layer.get_weights()\n",
        "new_layer_weights = pruned_weights[:, :, :22, :]\n",
        "new_layer_biases = pruned_biases[:22]\n",
        "new_layer.set_weights([new_layer_weights, new_layer_biases])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding a Flatten and Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_model.add(model.get_layer('flatten'))\n",
        "new_model.add(tf.keras.layers.Dense(10, activation='softmax', name='new_output'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "new_model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3793 - accuracy: 0.8655 - val_loss: 0.3168 - val_accuracy: 0.8838\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = new_model.fit(fashion_train_img, fashion_train_labels, epochs=1, validation_data=(fashion_test_img, fashion_test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pruned accuracy: 0.8838000297546387\n",
            "Time elapsed:  15.876929998397827\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the pruned model\n",
        "_, pruned_accuracy = new_model.evaluate(fashion_test_img, fashion_test_labels, verbose=0)\n",
        "print('Pruned accuracy:', pruned_accuracy)\n",
        "print('Time elapsed: ', end_time - start_time)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
