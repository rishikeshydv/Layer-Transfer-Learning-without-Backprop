{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rrvt3NUnAYTH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, Model\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras as K\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Title  \\\n",
      "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
      "1           1                    Crispy Salt and Pepper Potatoes   \n",
      "2           2                        Thanksgiving Mac and Cheese   \n",
      "3           3                 Italian Sausage and Bread Stuffing   \n",
      "4           4                                       Newton's Law   \n",
      "\n",
      "                                         Ingredients  \\\n",
      "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
      "1  ['2 large egg whites', '1 pound new potatoes (...   \n",
      "2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
      "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...   \n",
      "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Pat chicken dry with paper towels, season all ...   \n",
      "1  Preheat oven to 400°F and line a rimmed baking...   \n",
      "2  Place a rack in middle of oven; preheat to 400...   \n",
      "3  Preheat oven to 350°F with rack in middle. Gen...   \n",
      "4  Stir together brown sugar and hot water in a c...   \n",
      "\n",
      "                                          Image_Name  \\\n",
      "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
      "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
      "2         thanksgiving-mac-and-cheese-erick-williams   \n",
      "3          italian-sausage-and-bread-stuffing-240559   \n",
      "4                 newtons-law-apple-bourbon-cocktail   \n",
      "\n",
      "                                 Cleaned_Ingredients  \n",
      "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
      "1  ['2 large egg whites', '1 pound new potatoes (...  \n",
      "2  ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
      "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...  \n",
      "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n"
     ]
    }
   ],
   "source": [
    "#looking into data and its columns\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'datasets/source/kaggle_food.csv'\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to check the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
      "       'Cleaned_Ingredients'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will only be using 'Title' and 'Ingredients' for our purpose\n",
    "#so we will be dropping the remaining columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'Ingredients', 'Image_Name',\n",
    "       'Cleaned_Ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Instructions'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are creating a fake labels for temporary test\n",
    "#1/3 part of the labels to 'appetizers'. another 1/3 part to 'dinner' and the last 1/3 part to 'desserts'\n",
    "\n",
    "total_size = len(df)\n",
    "category_size = total_size // 3\n",
    "\n",
    "df.loc[:category_size - 1, 'Title'] = 'Appetizers'\n",
    "df.loc[category_size:2*category_size - 1, 'Title'] = 'Dinner'\n",
    "df.loc[2*category_size:total_size - 1, 'Title'] = 'Desserts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Title                                       Instructions\n",
      "0  Appetizers  Pat chicken dry with paper towels, season all ...\n",
      "1  Appetizers  Preheat oven to 400°F and line a rimmed baking...\n",
      "2  Appetizers  Place a rack in middle of oven; preheat to 400...\n",
      "3  Appetizers  Preheat oven to 350°F with rack in middle. Gen...\n",
      "4  Appetizers  Stir together brown sugar and hot water in a c...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the dataframe\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Assuming df['Instructions'] is your text data\n",
    "df['Instructions'].fillna('', inplace=True)  # Replace NaN values with an empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Title                                       Instructions\n",
      "13335    Desserts  Put oven rack in middle position and preheat o...\n",
      "4385   Appetizers  In a medium bowl, whisk together dry mix ingre...\n",
      "1175   Appetizers  Prepare a grill for medium-high heat. Brush ea...\n",
      "6557       Dinner  Combine short ribs, onion, prunes, and garlic ...\n",
      "11439    Desserts  In blender, purée olive oil, garlic, shallot, ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the parameters\n",
    "num_classes = 1\n",
    "embedding_dim = 100\n",
    "\n",
    "# Assuming df['Instructions'] is your text data, we  tokenize the input dataset into tokens for the CNN model\n",
    "#Tokenizer Initialization and Fitting:\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Instructions'])\n",
    "\n",
    "#Vocabulary Size and Maximum Sequence Length Calculation:\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_sequence_length = max(df['Instructions'].apply(lambda x: len(x.split())))\n",
    "\n",
    "#Texts to Sequences:\n",
    "sequences = tokenizer.texts_to_sequences(df['Instructions'])\n",
    "\n",
    "#Padding Sequences\n",
    "data = pad_sequences(sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'text' is your input data and 'label' is your target variable\n",
    "X = data   #data\n",
    "y = df['Title'].values           #labels \n",
    "\n",
    "# Convert labels to numerical format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer: Converts words into dense vectors of fixed size\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "\n",
    "# Convolutional layer with max pooling\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Fully connected layers for classification\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 2587, 100)         1327100   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2583, 128)         64128     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1399679 (5.34 MB)\n",
      "Trainable params: 1399679 (5.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 48s 142ms/step - loss: 0.0000e+00 - accuracy: 0.3362 - val_loss: 0.0000e+00 - val_accuracy: 0.3221\n"
     ]
    }
   ],
   "source": [
    "# Train the model and display the activations after each epoch\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 3s - loss: 0.0000e+00 - accuracy: 0.3221 - 3s/epoch - 39ms/step\n",
      "Test accuracy: 0.32210293412208557\n",
      "Time elapsed:  48.25538396835327\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Time elapsed: ', end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
