{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will be building a DANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, Model\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras as K\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Target Domain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             q                         queryTime  rank  \\\n",
      "0  dish recipe  2019-03-30 02:55:42.169989+00:00     1   \n",
      "1  dish recipe  2019-03-30 02:55:42.169989+00:00     2   \n",
      "2  dish recipe  2019-03-30 02:55:42.169989+00:00     3   \n",
      "3  dish recipe  2019-03-30 02:55:42.169989+00:00     4   \n",
      "4  dish recipe  2019-03-30 02:55:42.169989+00:00     5   \n",
      "\n",
      "                                               title  \\\n",
      "0                             7 Easy Chicken Dinners   \n",
      "1  KING of VEGETABLE Recipe | SAMBAR Recipe with ...   \n",
      "2  ALOO Manchurian Recipe How to make aloo manchu...   \n",
      "3  सूजी का इतना टेस्टी और आसान नाश्ता की आप रोज़ ...   \n",
      "4  5 मिनट में बनाये कुरकुरे आलू स्नैक्स | Aloo Sn...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Customize & buy the Tasty Cookbook here: http:...   \n",
      "1  Today we cooking one of the most popular veg r...   \n",
      "2  ldli Manchurian Recipe https://youtu.be/wx7Mx9...   \n",
      "3  Hello Friend's ….Aaj Main Aapko Quick & Easy B...   \n",
      "4  If you liked the video give it a thumbs up :) ...   \n",
      "\n",
      "                publishedAt             channelTitle  totalResults  \\\n",
      "0  2016-12-04T00:00:02.000Z                    Tasty       1000000   \n",
      "1  2019-03-26T15:50:35.000Z  Village Cooking Channel       1000000   \n",
      "2  2018-07-03T08:47:49.000Z          Foodies Hub CBR       1000000   \n",
      "3  2018-05-26T06:26:01.000Z         hemanshi's world       1000000   \n",
      "4  2017-05-23T15:20:50.000Z           Easy Home Tips       1000000   \n",
      "\n",
      "            kind                 channelId  ...  \\\n",
      "0  youtube#video  UCJFp8uSYCjXOMnkUyb3CQ3Q  ...   \n",
      "1  youtube#video  UCk3JZr7eS3pg5AGEvBdEvFg  ...   \n",
      "2  youtube#video  UCvO0ndRuwO8Prftc8rUCWIg  ...   \n",
      "3  youtube#video  UChDCj6lUL8qlZCdDeflNAwQ  ...   \n",
      "4  youtube#video  UCaKt8dvEIPnEHWSbLYhzrxg  ...   \n",
      "\n",
      "                                   channel.localized  \\\n",
      "0  {'title': 'Tasty', 'description': 'Food that\\'...   \n",
      "1  {'title': 'Village Cooking Channel', 'descript...   \n",
      "2  {'title': 'Foodies Hub CBR', 'description': 'H...   \n",
      "3  {'title': \"hemanshi's world\", 'description': '...   \n",
      "4  {'title': 'Easy Home Tips', 'description': 'We...   \n",
      "\n",
      "        channel.publishedAt  \\\n",
      "0  2016-01-22T23:05:31.000Z   \n",
      "1  2018-04-25T16:38:11.000Z   \n",
      "2  2016-10-03T02:55:57.000Z   \n",
      "3  2015-05-28T09:20:16.000Z   \n",
      "4  2016-09-13T07:44:33.000Z   \n",
      "\n",
      "                                  channel.thumbnails            channel.title  \\\n",
      "0  {'default': {'url': 'https://yt3.ggpht.com/a-/...                    Tasty   \n",
      "1  {'default': {'url': 'https://yt3.ggpht.com/a-/...  Village Cooking Channel   \n",
      "2  {'default': {'url': 'https://yt3.ggpht.com/a-/...          Foodies Hub CBR   \n",
      "3  {'default': {'url': 'https://yt3.ggpht.com/a-/...         hemanshi's world   \n",
      "4  {'default': {'url': 'https://yt3.ggpht.com/a-/...           Easy Home Tips   \n",
      "\n",
      "  channel.commentCount  channel.hiddenSubscriberCount channel.subscriberCount  \\\n",
      "0                    0                          False                13574044   \n",
      "1                    0                          False                  428301   \n",
      "2                    0                          False                  208140   \n",
      "3                    0                          False                  647768   \n",
      "4                    0                          False                 1783688   \n",
      "\n",
      "   channel.videoCount channel.viewCount  \\\n",
      "0                2832        2566200434   \n",
      "1                  73          51403646   \n",
      "2                 281          17710976   \n",
      "3                 504          52020675   \n",
      "4                 450         214856790   \n",
      "\n",
      "                            channel.relatedPlaylists  \n",
      "0  {'likes': 'LLJFp8uSYCjXOMnkUyb3CQ3Q', 'uploads...  \n",
      "1  {'uploads': 'UUk3JZr7eS3pg5AGEvBdEvFg', 'watch...  \n",
      "2  {'uploads': 'UUvO0ndRuwO8Prftc8rUCWIg', 'watch...  \n",
      "3  {'uploads': 'UUhDCj6lUL8qlZCdDeflNAwQ', 'watch...  \n",
      "4  {'uploads': 'UUaKt8dvEIPnEHWSbLYhzrxg', 'watch...  \n",
      "\n",
      "[5 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'datasets/target/recipes_serp_youtube_data.csv'\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df_target = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to check the data\n",
    "print(df_target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q', 'queryTime', 'rank', 'title', 'description', 'publishedAt',\n",
       "       'channelTitle', 'totalResults', 'kind', 'channelId', 'default.height',\n",
       "       'default.url', 'default.width', 'high.height', 'high.url', 'high.width',\n",
       "       'liveBroadcastContent', 'medium.height', 'medium.url', 'medium.width',\n",
       "       'nextPageToken', 'playlistId', 'resultsPerPage', 'thumbnails',\n",
       "       'videoId', 'video.contentDetails', 'video.etag', 'video.id',\n",
       "       'video.kind', 'video.localizations', 'video.player',\n",
       "       'video.recordingDetails', 'video.snippet', 'video.statistics',\n",
       "       'video.status', 'video.topicDetails', 'video.categoryId',\n",
       "       'video.channelId', 'video.channelTitle', 'video.defaultAudioLanguage',\n",
       "       'video.defaultLanguage', 'video.description',\n",
       "       'video.liveBroadcastContent', 'video.localized', 'video.publishedAt',\n",
       "       'video.tags', 'video.thumbnails', 'video.title',\n",
       "       'video.relevantTopicIds', 'video.topicCategories', 'video.topicIds',\n",
       "       'video.commentCount', 'video.dislikeCount', 'video.favoriteCount',\n",
       "       'video.likeCount', 'video.viewCount', 'video.embeddable',\n",
       "       'video.license', 'video.privacyStatus', 'video.publicStatsViewable',\n",
       "       'video.uploadStatus', 'video.caption', 'video.definition',\n",
       "       'video.dimension', 'video.duration', 'video.licensedContent',\n",
       "       'video.projection', 'video.regionRestriction',\n",
       "       'video.liveStreamingDetails', 'video.contentRating',\n",
       "       'channel.contentDetails', 'channel.etag', 'channel.id', 'channel.kind',\n",
       "       'channel.snippet', 'channel.statistics', 'channel.country',\n",
       "       'channel.customUrl', 'channel.defaultLanguage', 'channel.description',\n",
       "       'channel.localized', 'channel.publishedAt', 'channel.thumbnails',\n",
       "       'channel.title', 'channel.commentCount',\n",
       "       'channel.hiddenSubscriberCount', 'channel.subscriberCount',\n",
       "       'channel.videoCount', 'channel.viewCount', 'channel.relatedPlaylists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will only be using 'title' and 'video.tags' for our purpose\n",
    "#if you want to do DANN, use 'description' column as well so that the recipe & description are relevant to have similar features\n",
    "#so we will be dropping the remaining columns\n",
    "df_target = df_target.drop(columns=['q', 'queryTime', 'description','rank', 'publishedAt', 'channelTitle', 'totalResults', 'kind', 'channelId', 'default.height', 'default.url', 'default.width', 'high.height', 'high.url', 'high.width', 'liveBroadcastContent', 'medium.height', 'medium.url', 'medium.width', 'nextPageToken', 'playlistId', 'resultsPerPage', 'thumbnails', 'videoId', 'video.contentDetails', 'video.etag', 'video.id', 'video.kind', 'video.localizations', 'video.player', 'video.recordingDetails', 'video.snippet', 'video.statistics', 'video.status', 'video.topicDetails', 'video.categoryId', 'video.channelId', 'video.channelTitle', 'video.defaultAudioLanguage', 'video.defaultLanguage', 'video.description', 'video.liveBroadcastContent', 'video.localized', 'video.publishedAt', 'video.thumbnails', 'video.title', 'video.relevantTopicIds', 'video.topicCategories', 'video.topicIds', 'video.commentCount', 'video.dislikeCount', 'video.favoriteCount', 'video.likeCount', 'video.viewCount', 'video.embeddable', 'video.license', 'video.privacyStatus', 'video.publicStatsViewable', 'video.uploadStatus', 'video.caption', 'video.definition', 'video.dimension', 'video.duration', 'video.licensedContent', 'video.projection', 'video.regionRestriction', 'video.liveStreamingDetails', 'video.contentRating', 'channel.contentDetails', 'channel.etag', 'channel.id', 'channel.kind', 'channel.snippet', 'channel.statistics', 'channel.country', 'channel.customUrl', 'channel.defaultLanguage', 'channel.description', 'channel.localized', 'channel.publishedAt', 'channel.thumbnails', 'channel.title', 'channel.commentCount', 'channel.hiddenSubscriberCount', 'channel.subscriberCount', 'channel.videoCount', 'channel.viewCount', 'channel.relatedPlaylists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'video.tags'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df['Instructions'] is your text data\n",
    "df_target['video.tags'].fillna('', inplace=True)  # Replace NaN values with an empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are creating a fake labels for temporary test\n",
    "#1/3 part of the labels to 'appetizers'. another 1/3 part to 'dinner' and the last 1/3 part to 'desserts'\n",
    "\n",
    "total_size = len(df_target)\n",
    "category_size = total_size // 3\n",
    "df_target['labels'] = None\n",
    "df_target.loc[:category_size - 1, 'labels'] = 'Appetizers'\n",
    "df_target.loc[category_size:2*category_size - 1, 'labels'] = 'Dinner'\n",
    "df_target.loc[2*category_size:total_size - 1, 'labels'] = 'Desserts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   title  \\\n",
       "0                                7 Easy Chicken Dinners   \n",
       "1     KING of VEGETABLE Recipe | SAMBAR Recipe with ...   \n",
       "2     ALOO Manchurian Recipe How to make aloo manchu...   \n",
       "3     सूजी का इतना टेस्टी और आसान नाश्ता की आप रोज़ ...   \n",
       "4     5 मिनट में बनाये कुरकुरे आलू स्नैक्स | Aloo Sn...   \n",
       "...                                                 ...   \n",
       "1450                                    How to make pho   \n",
       "1451  Easy PHO 3 Ways! Beef, Chicken, Veggie (Vietna...   \n",
       "1452                                  Masterchef sadza.   \n",
       "1453  মিষ্টি দই বানানোর সহজ রেসিপি || How to make Sw...   \n",
       "1454  ১ ঘন্টায় চুলায় তৈরী বগুড়ার ঐতিহ্যবাহী মিষ্ট...   \n",
       "\n",
       "                                             video.tags      labels  \n",
       "0     ['chicken', 'dinner', 'tasty', 'buzzfeed', 'qu...  Appetizers  \n",
       "1     ['vegetable', 'vegetable recipe', 'sambar reci...  Appetizers  \n",
       "2                                                        Appetizers  \n",
       "3     ['Dahi wali bread', 'suji ka nashta', 'suji ka...  Appetizers  \n",
       "4     ['aloo', 'aloo snacks', 'potato', 'food', 'rec...  Appetizers  \n",
       "...                                                 ...         ...  \n",
       "1450  ['how', 'to', 'make', 'pho', 'vietnamese', 'fo...    Desserts  \n",
       "1451  ['easy chicken pho recipe how to make chicken ...    Desserts  \n",
       "1452                ['zimbabwean', 'sadza', 'cooking.']    Desserts  \n",
       "1453  ['দই বানানোর পদ্ধতি', 'দই না জমার কারন', 'মিষ্...    Desserts  \n",
       "1454  ['Dahi', 'mishti doi', 'doi make in oven', 'sw...    Desserts  \n",
       "\n",
       "[1455 rows x 3 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the dataframe\n",
    "df_target = df_target.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   title  \\\n",
       "497   Cooking &amp; Tasting Pork Belly Curry In My V...   \n",
       "1261                            How to Make a Braai Pie   \n",
       "411   Beef &amp; Guinness Stew - St. Patrick&#39;s D...   \n",
       "1046                  How to Make a Perfect Ratatouille   \n",
       "1033    How to make an Authentic bowl of VIETNAMESE PHO   \n",
       "...                                                 ...   \n",
       "1095                  Handle It - The Universal Poutine   \n",
       "1130  Super Simple Succotash -- Ridiculousy Easy &am...   \n",
       "1294  Jamaican Saltfish Fritters Recipe 2016 | Recip...   \n",
       "860   Authentic Spanish Seafood Paella Recipe - Cola...   \n",
       "1126          Ful Mudammas (Fuul) Ful Mudammas فول مدمس   \n",
       "\n",
       "                                             video.tags      labels  \n",
       "497   ['pork recipe', 'pork', 'pork belly', 'cooking...      Dinner  \n",
       "1261  ['Cooking (Interest)', 'How-to (Website Catego...    Desserts  \n",
       "411   ['Beef', 'Stew', 'Guinness', \"St. Patrick's Da...  Appetizers  \n",
       "1046  ['recipe', 'tasty', 'simple', 'easy', 'fast', ...    Desserts  \n",
       "1033  ['vietnamese pho recipe', 'how to cook vietnam...    Desserts  \n",
       "...                                                 ...         ...  \n",
       "1095  ['how to cook bacon', 'how to', 'cook bacon', ...    Desserts  \n",
       "1130  ['Chefs at Home', 'Succotash', 'Easy Side Dish...    Desserts  \n",
       "1294  ['Chef', 'Ricardo', 'Cooking', 'Caribbean', 'f...    Desserts  \n",
       "860   ['authentic', 'spanish', 'seafood', 'paella', ...      Dinner  \n",
       "1126  ['Quraac', 'Broad Beans', 'Healthy', 'وصفة', '...    Desserts  \n",
       "\n",
       "[1455 rows x 3 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#defining the parameters\n",
    "num_classes = 1\n",
    "embedding_dim = 100\n",
    "\n",
    "# Assuming df['Instructions'] is your text data, we  tokenize the input dataset into tokens for the CNN model\n",
    "#Tokenizer Initialization and Fitting:\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_target['title'])\n",
    "\n",
    "#Vocabulary Size and Maximum Sequence Length Calculation:\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_sequence_length = max(df_target['title'].apply(lambda x: len(x.split())))\n",
    "\n",
    "#Texts to Sequences:\n",
    "sequences = tokenizer.texts_to_sequences(df_target['title'])\n",
    "\n",
    "#Padding Sequences\n",
    "data = pad_sequences(sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'text' is your input data and 'label' is your target variable\n",
    "X = data   #data\n",
    "y = df_target['video.tags'].values           #labels \n",
    "\n",
    "# Convert labels to numerical format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_target, X_test_target, y_train_target, y_test_target = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer: Converts words into dense vectors of fixed size\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "\n",
    "# Convolutional layer with max pooling\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Fully connected layers for classification\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 8.5911e-04 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train the DANN\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train_target, y_train_target, epochs=1, validation_data=(X_test_target, y_test_target))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0000e+00 - accuracy: 0.0000e+00 - 21ms/epoch - 2ms/step\n",
      "Test accuracy: 0.0\n",
      "Time elapsed:  0.477125883102417\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "test_loss, test_acc = model.evaluate(X_test_target, y_test_target, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Time elapsed: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the auxiliary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Title  \\\n",
      "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
      "1           1                    Crispy Salt and Pepper Potatoes   \n",
      "2           2                        Thanksgiving Mac and Cheese   \n",
      "3           3                 Italian Sausage and Bread Stuffing   \n",
      "4           4                                       Newton's Law   \n",
      "\n",
      "                                         Ingredients  \\\n",
      "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
      "1  ['2 large egg whites', '1 pound new potatoes (...   \n",
      "2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
      "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...   \n",
      "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Pat chicken dry with paper towels, season all ...   \n",
      "1  Preheat oven to 400°F and line a rimmed baking...   \n",
      "2  Place a rack in middle of oven; preheat to 400...   \n",
      "3  Preheat oven to 350°F with rack in middle. Gen...   \n",
      "4  Stir together brown sugar and hot water in a c...   \n",
      "\n",
      "                                          Image_Name  \\\n",
      "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
      "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
      "2         thanksgiving-mac-and-cheese-erick-williams   \n",
      "3          italian-sausage-and-bread-stuffing-240559   \n",
      "4                 newtons-law-apple-bourbon-cocktail   \n",
      "\n",
      "                                 Cleaned_Ingredients  \n",
      "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
      "1  ['2 large egg whites', '1 pound new potatoes (...  \n",
      "2  ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
      "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...  \n",
      "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file_path.csv' with the actual path to your CSV file\n",
    "file_path = 'datasets/source/kaggle_food.csv'\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df_source = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to check the data\n",
    "print(df_source.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
       "       'Cleaned_Ingredients'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are not doing DANN, so we will just be using 'Instructions' column to build a topic space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will only be using 'Title' and 'Ingredients' for our purpose\n",
    "#so we will be dropping the remaining columns\n",
    "df_source = df_source.drop(columns=['Unnamed: 0', 'Ingredients', 'Image_Name',\n",
    "       'Cleaned_Ingredients','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df['Instructions'] is your text data\n",
    "df_source['Instructions'].fillna('', inplace=True)  # Replace NaN values with an empty string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a topic space and adding it as a column in df_source dataframe under the column 'topic_space'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rishikeshyadav/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df_source['topic_space'] = None\n",
    "\n",
    "# Assuming df['Instructions'] is your text data, we  tokenize the input dataset into tokens for the CNN model\n",
    "#Tokenizer Initialization and Fitting:\n",
    "tokenizer = Tokenizer()\n",
    "for i,instruction in enumerate(df_source['Instructions']):\n",
    "    tokens = word_tokenize(instruction)\n",
    "    \n",
    "    # Perform part-of-speech tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Filter out only nouns\n",
    "    nouns = [word for word, pos in pos_tags if pos.startswith('N')]\n",
    "\n",
    "    # Assign nouns to the 'topic_space' column for the current row\n",
    "    df_source.at[i, 'topic_space'] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pat',\n",
       " 'paper',\n",
       " 'towels',\n",
       " 'season',\n",
       " 'tsp',\n",
       " 'salt',\n",
       " 'legs',\n",
       " 'twine',\n",
       " 'sit',\n",
       " 'room',\n",
       " 'temperature',\n",
       " 'hour',\n",
       " 'squash',\n",
       " 'seeds',\n",
       " 'peeler',\n",
       " 'ridges',\n",
       " 'squash',\n",
       " 'halves',\n",
       " 'skin',\n",
       " 'Cut',\n",
       " 'half',\n",
       " 'wedges',\n",
       " 'arrange',\n",
       " 'baking',\n",
       " 'sheet',\n",
       " 'Combine',\n",
       " 'sage',\n",
       " 'Tbsp',\n",
       " 'butter',\n",
       " 'bowl',\n",
       " 'half',\n",
       " 'mixture',\n",
       " 'squash',\n",
       " 'sheet',\n",
       " 'Sprinkle',\n",
       " 'squash',\n",
       " 'allspice',\n",
       " 'pepper',\n",
       " 'flakes',\n",
       " '½',\n",
       " 'tsp',\n",
       " 'salt',\n",
       " 'season',\n",
       " 'pepper',\n",
       " 'toss',\n",
       " 'Add',\n",
       " 'bread',\n",
       " 'apples',\n",
       " 'oil',\n",
       " '¼',\n",
       " 'tsp',\n",
       " 'salt',\n",
       " 'herb',\n",
       " 'butter',\n",
       " 'bowl',\n",
       " 'season',\n",
       " 'pepper',\n",
       " 'toss',\n",
       " 'Set',\n",
       " 'Place',\n",
       " 'onion',\n",
       " 'vinegar',\n",
       " 'bowl',\n",
       " 'season',\n",
       " 'salt',\n",
       " 'toss',\n",
       " 'sit',\n",
       " 'rack',\n",
       " 'middle',\n",
       " 'third',\n",
       " 'oven',\n",
       " 'preheat',\n",
       " 'Mix',\n",
       " 'miso',\n",
       " 'Tbsp',\n",
       " 'room-temperature',\n",
       " 'butter',\n",
       " 'bowl',\n",
       " 'Pat',\n",
       " 'paper',\n",
       " 'towels',\n",
       " 'butter',\n",
       " 'Place',\n",
       " 'chicken',\n",
       " 'skillet',\n",
       " 'roast',\n",
       " 'rack',\n",
       " 'thermometer',\n",
       " 'part',\n",
       " 'breast',\n",
       " 'registers',\n",
       " 'minutes',\n",
       " 'Temperature',\n",
       " 'chicken',\n",
       " 'rests',\n",
       " 'rest',\n",
       " 'skillet',\n",
       " 'minutes',\n",
       " 'plate',\n",
       " 'skillet',\n",
       " 'roast',\n",
       " 'squash',\n",
       " 'rack',\n",
       " 'tender',\n",
       " 'minutes',\n",
       " 'mixture',\n",
       " 'layer',\n",
       " 'bread',\n",
       " 'brown',\n",
       " 'crisp',\n",
       " 'apples',\n",
       " 'tender',\n",
       " 'minutes',\n",
       " 'drain',\n",
       " 'onions',\n",
       " 'toss',\n",
       " 'dish',\n",
       " 'fingers',\n",
       " 'flour',\n",
       " 'butter',\n",
       " 'bowl',\n",
       " 'Set',\n",
       " 'skillet',\n",
       " 'drippings',\n",
       " 'medium',\n",
       " 'heat',\n",
       " 'cup',\n",
       " 'Add',\n",
       " 'wine',\n",
       " 'cook',\n",
       " 'bits',\n",
       " 'spoon',\n",
       " 'bits',\n",
       " 'wine',\n",
       " 'half',\n",
       " 'wine',\n",
       " 'minutes',\n",
       " 'Add',\n",
       " 'mixture',\n",
       " 'cook',\n",
       " 'paste',\n",
       " 'forms',\n",
       " 'minutes',\n",
       " 'Add',\n",
       " 'drippings',\n",
       " 'cook',\n",
       " 'minutes',\n",
       " 'heat',\n",
       " 'stir',\n",
       " 'miso',\n",
       " 'Taste',\n",
       " 'season',\n",
       " 'salt',\n",
       " 'pepper',\n",
       " 'Serve',\n",
       " 'chicken',\n",
       " 'panzanella',\n",
       " 'alongside']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source['topic_space'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
