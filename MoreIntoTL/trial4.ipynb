{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this trial, I am performing Domain Adaptatation Techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "rrvt3NUnAYTH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, Model\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import keras as K\n",
        "from tensorflow import keras\n",
        "#from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owOXRt4QAYTI",
        "outputId": "9785ce49-747f-4ca2-a461-69ed11c0918e"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to grayscale by taking the average of RGB channels\n",
        "train_images = np.mean(train_images, axis=-1, keepdims=True)\n",
        "test_images = np.mean(test_images, axis=-1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "#normalizing the datasets in the range of 0-1\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTtBH9-JAYTI"
      },
      "source": [
        "Defining our base  model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model below is an inspiration from tensorflow's functional models such as VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "def base_model(input_shape):\n",
        "    base_model = Sequential()\n",
        "    \n",
        "    base_model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(input_shape)))\n",
        "    base_model.add(BatchNormalization())\n",
        "    base_model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "    base_model.add(BatchNormalization())\n",
        "    base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    base_model.add(Dropout(0.25))\n",
        "\n",
        "    base_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "    base_model.add(BatchNormalization())\n",
        "    base_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "    base_model.add(BatchNormalization())\n",
        "    base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    base_model.add(Dropout(0.25))\n",
        "    base_model.add(Dense(64, activation='relu', name='dense_1'))\n",
        "    \n",
        "    return base_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining our Domain Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "def domain_classifier(input_shape):\n",
        "    # model = tf.keras.Sequential([\n",
        "    #     layers.Dense(128, activation='relu', input_shape=input_shape),\n",
        "    #     layers.Dense(1, activation='sigmoid')\n",
        "    # ])\n",
        "    dClassify = Sequential()\n",
        "   #dClassify.add(Flatten())\n",
        "    dClassify.add(Dense(64, activation='relu', name='dense_2',input_shape = (input_shape)))\n",
        "    dClassify.add(Dense(10, activation='softmax')) \n",
        "    \n",
        "    return dClassify\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DANN (Domain-Adversarial Neural Networks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dann_model(base_model, domain_classifier):\n",
        "    base_model.trainable = True\n",
        "    domain_classifier.trainable = True\n",
        "\n",
        "    input_image = layers.Input(shape=(input_shape))\n",
        "\n",
        "    # Feature extractor from base model\n",
        "    feature = base_model(input_image)\n",
        "\n",
        "    # Domain classifier\n",
        "    domain_output = domain_classifier(feature)\n",
        "\n",
        "    dann = Model(inputs=input_image, outputs=[feature, domain_output])\n",
        "    return dann\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = train_images.shape[1:]\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of the base model\n",
        "base_model_instance = base_model(input_shape)\n",
        "\n",
        "# Create an instance of the domain classifier\n",
        "domain_classifier_instance = domain_classifier((64,))  # Assuming the base model outputs 128-dimensional features\n",
        "\n",
        "# Create an instance of the DANN model\n",
        "dann = dann_model(base_model_instance, domain_classifier_instance)\n",
        "\n",
        "# Create domain labels for source and target data\n",
        "source_domain_labels = np.ones((len(train_images), 1))\n",
        "target_domain_labels = np.zeros((len(target_images), 1))\n",
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "dann.compile(optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.engine.input_layer.InputLayer at 0x296216ad0>,\n",
              " <keras.src.engine.sequential.Sequential at 0x296298f70>,\n",
              " <keras.src.engine.sequential.Sequential at 0x296298370>]"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dann.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_jlqhbAYTK",
        "outputId": "84265d3d-f2c0-4532-b4d8-f525a8030fbf"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_8' (type Functional).\n    \n    Input 0 of layer \"sequential_39\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 5, 5, 64)\n    \n    Call arguments received by layer 'model_8' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[169], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model and display the activations after each epoch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_domain_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_domain_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/__autograph_generated_filewr1l81hp.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_8' (type Functional).\n    \n    Input 0 of layer \"sequential_39\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 5, 5, 64)\n    \n    Call arguments received by layer 'model_8' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "dann.fit(train_images,[train_labels,source_domain_labels],\n",
        "         epochs=1,\n",
        "         validation_data=(test_images, [test_labels,target_domain_labels]))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC3DWd-ZAYTK",
        "outputId": "8c76a2e6-a254-4eea-f171-a1995bfd3f33"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_7' (type Functional).\n    \n    Input 0 of layer \"sequential_37\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 5, 5, 64)\n    \n    Call arguments received by layer 'model_7' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mdann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime elapsed: \u001b[39m\u001b[38;5;124m'\u001b[39m, end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/__autograph_generated_filefh_zkm6v.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_7' (type Functional).\n    \n    Input 0 of layer \"sequential_37\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 5, 5, 64)\n    \n    Call arguments received by layer 'model_7' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = dann.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db460>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x318f8d660>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db370>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x318fdf9d0>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x30651fdc0>,\n",
              " <keras.src.layers.regularization.dropout.Dropout at 0x3294db5b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294e1c00>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x286d7c040>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db490>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e851f910>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x2e852bf40>,\n",
              " <keras.src.layers.regularization.dropout.Dropout at 0x2e8517070>,\n",
              " <keras.src.layers.reshaping.flatten.Flatten at 0x29fed89d0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x29fedaad0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x29fedb220>]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, I will be performing JTL (Joint Transfer Learning) with FMNIST datasets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Fashion MNIST dataset\n",
        "(target_images, target_labels), (test0_images, test0_labels) = datasets.fashion_mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test0_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_images = target_images.reshape((60000,28,28,1))\n",
        "target_images = target_images/255.0\n",
        "\n",
        "test0_images = test0_images.reshape((10000,28,28,1))\n",
        "test0_images = test0_images/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DANN (Domain-Adversarial Neural Networks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(2):\n",
        "    base_model.pop()\n",
        "    \n",
        "#here we are using Feature-based Domain Adaptation Technique\n",
        "# here we try to distinguish between source and target domain data, forcing the model to learn domain-invariant features by adding and training new TOP_LAYERS\n",
        "\n",
        "\n",
        "# A Dense classifier - ten classes\n",
        "base_model.add(Dense(64, activation='relu', name='dense_1'))\n",
        "base_model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db460>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x318f8d660>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db370>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x318fdf9d0>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x30651fdc0>,\n",
              " <keras.src.layers.regularization.dropout.Dropout at 0x3294db5b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294e1c00>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x286d7c040>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x3294db490>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e851f910>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x2e852bf40>,\n",
              " <keras.src.layers.regularization.dropout.Dropout at 0x2e8517070>,\n",
              " <keras.src.layers.reshaping.flatten.Flatten at 0x29fed89d0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x30659a320>,\n",
              " <keras.src.layers.core.dense.Dense at 0x30658dc60>]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "base_model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_15\" is incompatible with the layer: expected shape=(None, 32, 32, 1), found shape=(32, 28, 28, 1)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model and display the activations after each epoch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/__autograph_generated_filewr1l81hp.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_15\" is incompatible with the layer: expected shape=(None, 32, 32, 1), found shape=(32, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "base_model.fit(train_images, train_labels, epochs=1, validation_data=(test_images, test_labels))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = base_model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, I will be performing JTL (Joint Transfer Learning) with SVHN datasets\n",
        "\n",
        "SVHN (Street View House Numbers): This dataset contains images of house numbers collected from Google Street View. It has 10 classes (0-9) and is somewhat similar to CIFAR-10 in terms of its small, cropped images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.datasets import svhn\n",
        "\n",
        "# Load the SVHN dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = svhn.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((6000,28,28,1))\n",
        "train_images = train_images/255.0\n",
        "\n",
        "test_images = test_images.reshape((54000,28,28,1))\n",
        "test_images = test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
        "\n",
        "# Split the training data into a 50:50 train-test split\n",
        "#train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.7, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to grayscale by taking the average of RGB channels\n",
        "train_images = np.mean(train_images, axis=-1, keepdims=True)\n",
        "test_images = np.mean(test_images, axis=-1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 32, 32, 1)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reusing the saved model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "loaded_model = keras.models.load_model('model_cifar.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956a890>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e951eb90>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956bdf0>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956b760>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956b520>\n",
            "<keras.src.layers.reshaping.flatten.Flatten object at 0x2e956bac0>\n",
            "<keras.src.layers.core.dense.Dense object at 0x2e956bc70>\n"
          ]
        }
      ],
      "source": [
        "for l in loaded_model.layers:\n",
        "    print(l)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorflow.keras.layers import Dense,Flatten\n",
        "# from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "#making changes in the layers of the pre-saved model\n",
        "for i in range(2):\n",
        "    loaded_model.pop()\n",
        "\n",
        "#here we are using the same lower layer layers of the initial model but adding a new top fully connected layers\n",
        "#so as to adapt with the new target domain\n",
        "\n",
        "# x = loaded_model.layers[-3].output \n",
        "# x = Flatten()(x)\n",
        "# x = Dense(64,activation='relu',name='dense_1')\n",
        "# predictions = Dense(10, activation = \"softmax\")(x)\n",
        "# final_model = Model(inputs = loaded_model.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #adding new flatten and dense layers to help the model adapt the target domain\n",
        "loaded_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "loaded_model.add(tf.keras.layers.Dense(64, activation='relu', name='dense_1'))\n",
        "loaded_model.add(tf.keras.layers.Dense(100, activation='softmax', name='output'))\n",
        "# #loaded_model.add(tf.keras.layers.Dense(128, activation='relu', name='dense_2'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956a890>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e951eb90>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956bdf0>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956b760>\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2e956b520>\n",
            "<keras.src.layers.reshaping.flatten.Flatten object at 0x2e9568250>\n",
            "<keras.src.layers.core.dense.Dense object at 0x2e9568e50>\n",
            "<keras.src.layers.core.dense.Dense object at 0x2d4471600>\n"
          ]
        }
      ],
      "source": [
        "for l in loaded_model.layers:\n",
        "    print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "#here we freeze the convolutional layers so that its weights and biases are not affected\n",
        "#we only want to have the top fully connected adjusted as per the target\n",
        "for layer in loaded_model.layers[:5]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "loaded_model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "469/469 [==============================] - 45s 96ms/step - loss: 4.1889 - accuracy: 0.0759 - val_loss: 3.7594 - val_accuracy: 0.1390\n",
            "Epoch 2/3\n",
            "469/469 [==============================] - 46s 98ms/step - loss: 3.3958 - accuracy: 0.2083 - val_loss: 3.5536 - val_accuracy: 0.1754\n",
            "Epoch 3/3\n",
            "469/469 [==============================] - 45s 97ms/step - loss: 2.7791 - accuracy: 0.3209 - val_loss: 3.6499 - val_accuracy: 0.1814\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "loaded_model.fit(train_images, train_labels, epochs=3, validation_data=(test_images, test_labels))\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 51s 36ms/step - loss: 4.5288 - accuracy: 0.1516\n",
            "Test accuracy: 0.15164443850517273\n",
            "Time elapsed:  580.2481989860535\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = loaded_model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
