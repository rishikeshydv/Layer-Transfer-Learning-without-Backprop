{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this trial, I am performing Domain Adaptatation Techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "rrvt3NUnAYTH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, Model\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import keras as K\n",
        "from tensorflow import keras\n",
        "#from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing import image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owOXRt4QAYTI",
        "outputId": "9785ce49-747f-4ca2-a461-69ed11c0918e"
      },
      "outputs": [],
      "source": [
        "#defining training and testing datasets\n",
        "(x_train, y_train), (x_test,y_test) = datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {},
      "outputs": [],
      "source": [
        "#adding 4th dimension as 1 to declare as grayscale image\n",
        "#normalizing the images\n",
        "x_train = x_train.reshape((60000, 28, 28, 1))\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test.reshape((10000, 28, 28, 1))\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1', trainable = False),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_2', trainable = False),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_3', trainable = False),\n",
        "    tf.keras.layers.Flatten(name='flatten'),\n",
        "    # tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
        "    tf.keras.layers.Dense(47, activation='softmax', name='output')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3257 - accuracy: 0.9189 - val_loss: 0.1766 - val_accuracy: 0.9517\n"
          ]
        }
      ],
      "source": [
        "# Train the model and display the activations after each epoch\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.1766 - accuracy: 0.9517 - 1s/epoch - 5ms/step\n",
            "Test accuracy: 0.95169997215271\n",
            "Time elapsed:  12.85428500175476\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Time elapsed: ', end_time - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # %pip install emnist\n",
        "# import emnist\n",
        "# from emnist import extract_training_samples\n",
        "# from emnist import extract_test_samples\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(test_img, test_labels), (_, _) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {},
      "outputs": [],
      "source": [
        "# emnist.list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #using EMNIST (Extended MNIST) dataset\n",
        "# target_img,target_labels = extract_training_samples('digits')\n",
        "# #test_img,test_labels = extract_test_samples('letters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reshaping the datasets\n",
        "test_img = test_img.reshape((60000, 28, 28, 1))\n",
        "test_img = test_img / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to generate dummy labels\n",
        "def generate_dummy_labels(num_samples, num_classes):\n",
        "    return np.random.randint(0, num_classes, num_samples)\n",
        "\n",
        "# Assuming num_classes in EMNIST is 26 for letters\n",
        "num_classes_emnist = 10\n",
        "\n",
        "# Generate dummy labels for EMNIST\n",
        "dummy_labels = generate_dummy_labels(test_img.shape[0], num_classes_emnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 - 9s - loss: 6.1756 - accuracy: 0.1001 - 9s/epoch - 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#testing with no labels\n",
        "test_loss, test_acc = model.evaluate(test_img, dummy_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see the accuracy is pretty poor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 - 9s - loss: 6.1824 - accuracy: 0.0728 - 9s/epoch - 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#testing with labels\n",
        "test_loss, test_acc = model.evaluate(test_img, test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see the accuracy is still not great."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "Predicted label: 3\n"
          ]
        }
      ],
      "source": [
        "#predicting the label of a number based image\n",
        "# Load and preprocess the input image\n",
        "img_path = 'num1.png'\n",
        "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x /= 255.0\n",
        "\n",
        "# Predict the label\n",
        "predictions = model.predict(x)\n",
        "predicted_label = np.argmax(predictions[0])\n",
        "\n",
        "print(f'Predicted label: {predicted_label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's build a DANN now and examine the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Feature Extractor\n",
        "def build_feature_extractor(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape,name='conv2d_1'),\n",
        "        layers.Conv2D(32, (3,3), activation='relu',name='conv2d_2'),\n",
        "        layers.Conv2D(32, (3,3), activation='relu',name='conv2d_3'),\n",
        "        layers.Flatten(name='flatten')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Label Predictor\n",
        "def build_label_predictor(num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(num_classes, activation='softmax',name='output')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Domain Predictor\n",
        "def build_domain_predictor():\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu',name='dense_1'),\n",
        "        layers.Dense(1, activation='sigmoid',name='dense_2')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the complete DANN model\n",
        "def build_dann(input_shape, num_classes):\n",
        "    feature_extractor = build_feature_extractor(input_shape)\n",
        "    label_predictor = build_label_predictor(num_classes)\n",
        "    domain_predictor = build_domain_predictor()\n",
        "\n",
        "    # Define inputs\n",
        "    input_data = layers.Input(shape=input_shape)\n",
        "    label = layers.Input(shape=(num_classes,))\n",
        "    domain_label = layers.Input(shape=(1,))\n",
        "    \n",
        "    # Feature extractor output\n",
        "    feature_output = feature_extractor(input_data)\n",
        "    \n",
        "    # Label prediction branch\n",
        "    label_output = label_predictor(feature_output)\n",
        "    \n",
        "    # Domain prediction branch\n",
        "    domain_output = domain_predictor(feature_output)\n",
        "    \n",
        "    dann_model = models.Model(inputs=[input_data, label, domain_label], \n",
        "                              outputs=[label_output, domain_output])\n",
        "    \n",
        "    return dann_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss functions\n",
        "def label_loss(y_true, y_pred):\n",
        "    return tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "def domain_loss(y_true, y_pred):\n",
        "    return tf.keras.losses.binary_crossentropy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build and compile the DANN model\n",
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "\n",
        "dann_model = build_dann(input_shape, num_classes)\n",
        "\n",
        "dann_model.compile(optimizer='Adam',\n",
        "                   loss=[label_loss, domain_loss],\n",
        "                   loss_weights=[1.0,0.1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare domain labels\n",
        "domain_label_source = np.zeros((x_train.shape[0], 1))  # Source domain label is 0\n",
        "domain_label_target = np.ones((test_img.shape[0], 1))   # Target domain label is 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-hot encode the train labels\n",
        "#shape of y_train is (6000,) initially despite having 10 classes\n",
        "# it means that it contains class labels as integers rather than being one-hot encoded.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate source and target data\n",
        "x_combined = np.vstack((x_train, test_img))\n",
        "y_combined = np.vstack((y_train, np.zeros((y_train.shape))))  # Labels for target domain can be ignored\n",
        "domain_labels_combined = np.vstack((domain_label_source, domain_label_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/ipykernel_84611/2340007477.py\", line 3, in label_loss  *\n        return tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 28, 28, 1) and (32, 10) are incompatible\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[448], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the DANN\u001b[39;00m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdann_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdomain_labels_combined\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/__autograph_generated_file_kzzdgc2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/__autograph_generated_file0jhirp2t.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__label_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mcategorical_crossentropy, (ag__\u001b[39m.\u001b[39mld(y_true), ag__\u001b[39m.\u001b[39mld(y_pred)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/ipykernel_84611/2340007477.py\", line 3, in label_loss  *\n        return tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 28, 28, 1) and (32, 10) are incompatible\n"
          ]
        }
      ],
      "source": [
        "# Train the DANN\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "dann_model.fit([x_combined,y_combined,domain_labels_combined], \n",
        "               [x_combined,y_combined], \n",
        "               epochs=1)\n",
        "\n",
        "end_time = time.time()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
